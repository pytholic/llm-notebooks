{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Codebase Security Analyzer with Gemini-1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook implements a sophisticated security analysis tool that leverages Google's Gemini 1.5 Pro LLM to perform comprehensive security assessments of Python codebases. The analyzer processes entire repositories, examining multiple file types including Python source code, configuration files, Docker configurations, CI/CD pipelines, dependencies, and potential secret-containing files. It utilizes Gemini's large context window to analyze security vulnerabilities, coding patterns, and potential risks across the entire codebase.\n",
    "\n",
    "**Why Long Context?** \n",
    "The long context window capability is particularly crucial for this security analysis use case as it enables:\n",
    "1. Holistic Pattern Recognition: The ability to analyze multiple files simultaneously allows detection of security vulnerabilities that span across different components and configurations\n",
    "2. Cross-Reference Analysis: Understanding how different parts of the codebase interact helps identify security implications of shared dependencies and architectural decisions\n",
    "3. Comprehensive Context: Security issues often emerge from the interaction between multiple components - having the full context helps avoid false positives and identify complex vulnerability patterns\n",
    "4. Efficient Processing: Instead of analyzing files in isolation and trying to piece together the findings, the long context window allows for more natural and accurate security assessment that considers the entire system architecture\n",
    "\n",
    "**Key Features**\n",
    "\n",
    "- Holistic repository analysis with support for multiple file types\n",
    "- Advanced security vulnerability detection using Gemini 1.5 Pro\n",
    "- Categorized analysis of different file types (code, configs, Docker, CI/CD, etc.)\n",
    "- Intelligent handling of potential secret-containing files\n",
    "- Comprehensive security report generation in Markdown format\n",
    "- Built-in retry mechanisms and error handling\n",
    "- Support for large codebases with efficient file processing\n",
    "- Reduces API calls and improves response time with context caching\n",
    "\n",
    "The tool is designed to help security analysts, developers, and DevOps teams identify potential security issues early in the development lifecycle, providing actionable insights and recommendations for improving codebase security."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup and Installation\n",
    "First, we will install the required packages and and set up our generation api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "\n",
    "# !pip install google-generativeai tenacity gitpython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import fnmatch\n",
    "import tempfile\n",
    "import time\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "from datetime import timedelta\n",
    "import google.generativeai.caching as caching\n",
    "\n",
    "import git\n",
    "import google.generativeai as genai\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Security Analyzer Class\n",
    "\n",
    "We will now implement the `ComprehensiveSecurityAnalyzer`. This class represents a sophisticated security analysis tool leveraging Gemini's advanced language model capabilities. It processes entire codebases holistically, moving beyond traditional file-by-file analysis to identify cross-cutting security concerns. The analyzer categorizes and examines multiple file types including Python source code, configuration files, Docker configurations, CI/CD pipelines, dependencies, documentation, and potential secret-containing files. Using Gemini's long context window, it performs nuanced security assessments across file boundaries, detecting vulnerabilities, patterns, and potential risks that might be missed in isolated analysis. The tool implements robust error handling, retry mechanisms for API reliability, context caching for performance optimization, and generates detailed security reports in Markdown format. This comprehensive approach helps security teams and developers identify potential security issues early in the development lifecycle.\n",
    "\n",
    "**Context Caching**\n",
    "The implementation demonstrates efficient context management through a sophisticated caching system that optimizes API interactions with the Gemini model. The analyzer intelligently processes and caches content with configurable size limits (100KB per file, 1MB total), preventing memory overload while maintaining analysis quality. Files are organized by category and cached with relevant security context, enabling faster subsequent analyses. The system includes automatic TTL-based cache invalidation and graceful fallback mechanisms, ensuring reliable performance even when handling large codebases. This approach significantly reduces API calls and improves response times while maintaining the context necessary for accurate security analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "ℹ️ I had to put the limits on the context caching, or else i was getting 500 INTERNAL SERVER issues. Of course there can be better ways to resolve this but to lack of time and resources, I had to rely on the limit approach\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Enums for file categories and pattern keys\n",
    "# This will help us to not repeat the same strings in multiple places and make it easier to maintain\n",
    "\n",
    "from enum import StrEnum\n",
    "\n",
    "class FileCategory(StrEnum):\n",
    "    \"\"\"Enumeration of file categories for security analysis.\"\"\"\n",
    "    CODE = 'code'\n",
    "    CONFIG = 'config'\n",
    "    DOCKER = 'docker'\n",
    "    CI_CD = 'ci_cd'\n",
    "    DEPENDENCIES = 'dependencies'\n",
    "    DOCUMENTATION = 'documentation'\n",
    "    POTENTIAL_SECRETS = 'potential_secrets'\n",
    "\n",
    "class FilePatternKey(StrEnum):\n",
    "    \"\"\"Enumeration of keys used in file pattern dictionary.\"\"\"\n",
    "    CODE = 'code_files'\n",
    "    CONFIG = 'config_files'\n",
    "    DOCKER = 'docker_files'\n",
    "    CI = 'ci_files'\n",
    "    DEPENDENCIES = 'dependency_files'\n",
    "    DOCS = 'docs'\n",
    "    SECRETS = 'secrets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ComprehensiveSecurityAnalyzer:\n",
    "    \"\"\"A comprehensive security analysis tool that leverages Gemini 1.5 Pro to analyze entire codebases for security vulnerabilities.\n",
    "\n",
    "    This class handles repository cloning, file categorization, and security analysis across multiple file types including source code, configurations, Docker files, CI/CD configurations, dependencies, documentation, and potential secret-containing files.\n",
    "\n",
    "    The analyzer uses pattern matching and pathlib for efficient file processing, implements retry mechanisms for API reliability, and generates detailed security reports in Markdown format. It's designed to process files up to 1MB in size and uses UTF-8  encoding with error handling for maximum compatibility.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    gemini_api_key : str\n",
    "        API key for the Gemini 1.5 Pro model.\n",
    "    repo_path : Optional[str], default=None\n",
    "        Path to the cloned repository.\n",
    "    temp_dir : str, default=tempfile.mkdtemp(dir=\".\")\n",
    "        Temporary directory to store cloned repositories and analysis results.\n",
    "    MAX_CONTENT_SIZE : int, default=100_000\n",
    "        Maximum content size in bytes for caching.\n",
    "    MAX_TOTAL_SIZE : int, default=1_000_000\n",
    "        Maximum total size in bytes for caching.\n",
    "    model_name : str, default=\"models/gemini-1.5-pro-001\" \n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    clone_repository(repo_url: str) -> Path\n",
    "        Clone a repository from a given URL.\n",
    "    gather_relevant_files() -> dict[str, list[dict[str, str]]]\n",
    "        Gather relevant files from the cloned repository.\n",
    "    analyze_security() -> str\n",
    "        Perform security analysis category by category.\n",
    "    cleanup()\n",
    "        Clean up temporary files.\n",
    "    _categorize_file(file_path: str) -> Optional[str]\n",
    "        Categorize a file based on its path.\n",
    "    _analyze_category(category: str, files: list) -> str\n",
    "        Analyze a category of files for security vulnerabilities.\n",
    "    _get_category_checklist(category: str) -> str\n",
    "        Get a checklist of security aspects for a given category.\n",
    "    _create_context_cache(files_by_category: dict)\n",
    "        Create cached context with size limits and error handling.\n",
    "    \"\"\"\n",
    "\n",
    "    gemini_api_key: str\n",
    "    repo_path: Optional[str] = None\n",
    "    temp_dir: str = field(default_factory=lambda: tempfile.mkdtemp(dir=\".\"))\n",
    "    MAX_CONTENT_SIZE = 100_000  # ~100KB limit per content piece\n",
    "    MAX_TOTAL_SIZE = 1_000_000  # ~1MB total context limit\n",
    "    model_name: str = \"models/gemini-1.5-pro-001\"\n",
    "\n",
    "    def __post_init__(self):\n",
    "        # configure gemini key\n",
    "        genai.configure(api_key=self.gemini_api_key)\n",
    " \n",
    "    def _create_context_cache(self, files_by_category: dict) -> None:\n",
    "        \"\"\"Create cached context with size limits and error handling\"\"\"\n",
    "        try:\n",
    "            # Prepare content for caching with size limits\n",
    "            contents = []\n",
    "            total_size = 0\n",
    "            \n",
    "            for category, files in files_by_category.items():\n",
    "                category_content = []\n",
    "                for file in files:\n",
    "                    # Skip large files\n",
    "                    if len(file['content']) > self.MAX_CONTENT_SIZE:\n",
    "                        continue\n",
    "                        \n",
    "                    file_content = f\"\\n## {file['path']}\\n```\\n{file['content'][:self.MAX_CONTENT_SIZE]}```\\n\"\n",
    "                    if total_size + len(file_content) < self.MAX_TOTAL_SIZE:\n",
    "                        category_content.append(file_content)\n",
    "                        total_size += len(file_content)\n",
    "                    else:\n",
    "                        break\n",
    "                \n",
    "                if category_content:\n",
    "                    contents.append(f\"\\n# {category.upper()} FILES\\n{''.join(category_content)}\")\n",
    "\n",
    "            if not contents:\n",
    "                raise ValueError(\"No content within size limits for caching\")\n",
    "\n",
    "            # Create cache with error handling\n",
    "            self._context_cache = caching.CachedContent.create(\n",
    "                model=self.model_name,\n",
    "                display_name=\"Security Analysis Context\",\n",
    "                system_instruction=(\n",
    "                    \"You are a security expert analyzing code for vulnerabilities. \"\n",
    "                    \"Focus on security risks and provide specific recommendations.\"\n",
    "                ),\n",
    "                contents=contents[:5],  # Limit number of content pieces\n",
    "                ttl=timedelta(minutes=30)  # Reduced cache time\n",
    "            )\n",
    "\n",
    "            # Create model with cached context\n",
    "            self.model = genai.GenerativeModel.from_cached_content(\n",
    "                cached_content=self._context_cache\n",
    "            )\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Context caching failed: {e}\")\n",
    "            # Fallback to regular model\n",
    "            self.model = genai.GenerativeModel(\n",
    "                model_name=self.model_name\n",
    "            )\n",
    "            \n",
    "    # Define file patterns to analyze\n",
    "    file_patterns = {\n",
    "        FilePatternKey.CODE.value: {\n",
    "            \".py\",  # Python source\n",
    "            \".pyx\",  # Cython source\n",
    "            \".pyi\",  # Python interface\n",
    "            \".ipynb\",  # Jupyter notebook\n",
    "        },\n",
    "        FilePatternKey.CONFIG.value: {\n",
    "            \".yml\",\n",
    "            \".yaml\",\n",
    "            \".json\",\n",
    "            \".env\",\n",
    "            \".ini\",\n",
    "            \".toml\",\n",
    "            \".cfg\",\n",
    "            \".conf\",\n",
    "            \".properties\",\n",
    "        },\n",
    "        FilePatternKey.DOCKER.value: {\"Dockerfile\", \"docker-compose.yml\", \"docker-compose.yaml\"},\n",
    "        FilePatternKey.CI.value: {\n",
    "            \".github/workflows/*.yml\",\n",
    "            \".github/workflows/*.yaml\",\n",
    "            \"**/Jenkinsfile\",\n",
    "            \".gitlab-ci.yml\",\n",
    "            \"azure-pipelines.yml\",\n",
    "            \".circleci/config.yml\",\n",
    "            \".travis.yml\",\n",
    "        },\n",
    "        FilePatternKey.DEPENDENCIES.value: {\n",
    "            \"requirements.txt\",\n",
    "            \"setup.py\",\n",
    "            \"pyproject.toml\",\n",
    "            \"Pipfile\",\n",
    "            \"poetry.lock\",\n",
    "            \"requirements/*.txt\",\n",
    "            \"requirements/**/*.txt\",\n",
    "            \"setup.cfg\",\n",
    "            \"constraints.txt\",\n",
    "        },\n",
    "        FilePatternKey.DOCS.value: {\".md\", \".rst\", \".txt\", \".pdf\", \".doc\", \".docx\"},\n",
    "        FilePatternKey.SECRETS.value: {\n",
    "            \"**/*.env\",\n",
    "            \".env.*\",\n",
    "            \"**/*.pem\",\n",
    "            \"**/*.key\",\n",
    "            \"**/secrets.*\",\n",
    "            \"**/*.cert\",\n",
    "            \"**/*.p12\",\n",
    "            \"**/*.pfx\",\n",
    "            \"**/id_rsa\",\n",
    "            \"**/id_dsa\",\n",
    "            \"**/id_ecdsa\",\n",
    "            \"**/id_ed25519\",\n",
    "        },\n",
    "    }\n",
    "\n",
    "    def clone_repository(self, repo_url: str) -> Path:\n",
    "        \"\"\"Clone a repository from a given URL.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        repo_url : str\n",
    "            URL of the repository to clone.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Path\n",
    "            Path to the cloned repository.\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        Exception\n",
    "            If the repository cloning fails.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            if not self.repo_path:\n",
    "                self.repo_path = Path(self.temp_dir) / Path(repo_url).name\n",
    "                git.Repo.clone_from(repo_url, self.repo_path)\n",
    "                return self.repo_path\n",
    "            else:\n",
    "                print(\"Repository already cloned.\")\n",
    "        except git.GitCommandError as e:\n",
    "            raise Exception(f\"Failed to clone repository: {str(e)}\")\n",
    "\n",
    "    def gather_relevant_files(self) -> dict[str, list[dict[str, str]]]:\n",
    "        \"\"\"Gather relevant files from the cloned repository.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict[str, list[dict[str, str]]]\n",
    "            A dictionary containing files grouped by category.\n",
    "        \"\"\"\n",
    "\n",
    "        files_by_category = {category.value: [] for category in FileCategory}\n",
    "\n",
    "        # Skip common non-source directories\n",
    "        skip_dirs = {\".git\", \"build\", \"dist\", \"__pycache__\", \"*.egg-info\"}\n",
    "\n",
    "        # Use pathlib's rglob to recursively get all files\n",
    "        for file_path in Path(self.repo_path).rglob(\"*\"):\n",
    "            # Skip directories and files in skip_dirs\n",
    "            if any(parent.name in skip_dirs for parent in file_path.parents):\n",
    "                continue\n",
    "\n",
    "            # Skip directories, only process files\n",
    "            if not file_path.is_file():\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # Skip large files (> 1MB)\n",
    "                if file_path.stat().st_size > 1_000_000:\n",
    "                    continue\n",
    "\n",
    "                # Get relative path\n",
    "                relative_path = file_path.relative_to(self.repo_path)\n",
    "\n",
    "                # Read file content\n",
    "                try:\n",
    "                    content = file_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "                except UnicodeDecodeError:\n",
    "                    # Skip binary files\n",
    "                    continue\n",
    "\n",
    "                file_info = {\"path\": str(relative_path), \"content\": content}\n",
    "\n",
    "                # Categorize file using pattern matching\n",
    "                category = self._categorize_file(str(relative_path))\n",
    "                if category:\n",
    "                    files_by_category[category].append(file_info)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {file_path}: {e}\")\n",
    "\n",
    "        return files_by_category\n",
    "\n",
    "    def _categorize_file(self, file_path: str) -> Optional[str]:\n",
    "        \"\"\"Categorize a file based on its path.\"\"\"\n",
    "        path = Path(file_path)\n",
    "\n",
    "        match path:\n",
    "            case _ if path.suffix in self.file_patterns[FilePatternKey.CODE.value]:\n",
    "                return FileCategory.CODE.value\n",
    "            case _ if path.suffix in self.file_patterns[FilePatternKey.CONFIG.value]:\n",
    "                return FileCategory.CONFIG.value\n",
    "            case _ if path.name in self.file_patterns[FilePatternKey.DOCKER.value]:\n",
    "                return FileCategory.DOCKER.value\n",
    "            case _ if any(\n",
    "                fnmatch.fnmatch(file_path, pattern)\n",
    "                for pattern in self.file_patterns[FilePatternKey.CI.value]\n",
    "            ):\n",
    "                return FileCategory.CI_CD.value\n",
    "            case _ if path.name in self.file_patterns[FilePatternKey.DEPENDENCIES.value]:\n",
    "                return FileCategory.DEPENDENCIES.value\n",
    "            case _ if path.suffix in self.file_patterns[FilePatternKey.DOCS.value]:\n",
    "                return FileCategory.DOCUMENTATION.value\n",
    "            case _ if any(\n",
    "                fnmatch.fnmatch(file_path, pattern)\n",
    "                for pattern in self.file_patterns[FilePatternKey.SECRETS.value]\n",
    "            ):\n",
    "                return FileCategory.POTENTIAL_SECRETS.value\n",
    "            case _:\n",
    "                return None\n",
    "\n",
    "    @retry(\n",
    "        stop=stop_after_attempt(3),\n",
    "        wait=wait_exponential(multiplier=1, min=4, max=10),\n",
    "        reraise=True,\n",
    "    )\n",
    "    def _analyze_category(self, category: str, files: list, retry_count: int | None = 3) -> str:\n",
    "        \"\"\"Analyze a category of files for security vulnerabilities.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        category : str\n",
    "            Category of files to analyze.\n",
    "        files : list\n",
    "            List of files to analyze.\n",
    "        retry_count : int, optional\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Analysis report in Markdown format.\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Generate prompt for the category\n",
    "            category_files = \"\\n\\n\".join(\n",
    "                f\"### {file['path']}\\n```\\n{file['content']}\\n```\" for file in files\n",
    "            )\n",
    "\n",
    "            prompt = f\"\"\"\n",
    "            Analyze these {category.upper()} FILES for security vulnerabilities:\n",
    "\n",
    "            Files to analyze:\n",
    "            {category_files}\n",
    "\n",
    "            Provide analysis focusing on relevant security aspects for {category} files:\n",
    "            {self._get_category_checklist(category)}\n",
    "\n",
    "            Format the response in Markdown with:\n",
    "            1. CRITICAL FINDINGS\n",
    "            2. HIGH-RISK ISSUES\n",
    "            3. MEDIUM CONCERNS\n",
    "            4. RECOMMENDATIONS\n",
    "            \"\"\"\n",
    "\n",
    "            # Generate content using the model\n",
    "            response = self.model.generate_content(prompt)\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            if retry_count > 0:\n",
    "                print(f\"Retrying {category} analysis... ({retry_count} attempts left)\")\n",
    "                time.sleep(5)  # Add delay between retries\n",
    "                return self._analyze_category(category, files, retry_count - 1)\n",
    "            raise e\n",
    "\n",
    "    def _get_category_checklist(self, category: str) -> str:\n",
    "        \"\"\"Get a checklist of security aspects for a given category.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        category : str\n",
    "            Category of files to analyze.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Checklist of security aspects for the category.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        checklists = {\n",
    "            FileCategory.CODE.value: \"\"\"\n",
    "                - Input validation\n",
    "                - Authentication/Authorization\n",
    "                - Data sanitization\n",
    "                - Secure coding practices\n",
    "                - Error handling\n",
    "                - Cryptographic implementations\n",
    "            \"\"\",\n",
    "            FileCategory.CONFIG.value: \"\"\"\n",
    "                - Hardcoded credentials\n",
    "                - Insecure defaults\n",
    "                - Exposed sensitive information\n",
    "                - Misconfiguration risks\n",
    "            \"\"\",\n",
    "            FileCategory.DOCKER.value: \"\"\"\n",
    "                - Root/privileged execution\n",
    "                - Exposed ports\n",
    "                - Base image security\n",
    "                - Build-time secrets\n",
    "            \"\"\",\n",
    "            FileCategory.CI_CD.value: \"\"\"\n",
    "                - Secret management\n",
    "                - Secure pipeline practices\n",
    "                - Security testing integration\n",
    "            \"\"\",\n",
    "            FileCategory.DEPENDENCIES.value: \"\"\"\n",
    "                - Known vulnerable dependencies\n",
    "                - Supply chain risks\n",
    "                - Version constraints\n",
    "            \"\"\",\n",
    "            FileCategory.DOCUMENTATION.value: \"\"\"\n",
    "                - Exposed sensitive info\n",
    "                - Security misconfigurations\n",
    "                - Outdated practices\n",
    "            \"\"\",\n",
    "            FileCategory.POTENTIAL_SECRETS.value: \"\"\"\n",
    "                - API keys\n",
    "                - Access tokens\n",
    "                - Credentials\n",
    "                - Private keys\n",
    "            \"\"\",\n",
    "        }\n",
    "        return checklists.get(category, \"\")\n",
    "\n",
    "    def analyze_security(self) -> str:\n",
    "        \"\"\"Perform security analysis category by category\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Path to the generated security analysis report.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        - The report is generated in Markdown format.\n",
    "        - We are generating report separately for each category. I faced quota and timeout issues when generating report for all categories at once.\n",
    "\n",
    "        \"\"\"\n",
    "        try:\n",
    "            files_by_category = self.gather_relevant_files()\n",
    "            report_path = Path(f\"./security_analysis_{Path(self.repo_path).name}.md\")\n",
    "\n",
    "            # Create context cache for analysis\n",
    "            self._create_context_cache(files_by_category)\n",
    "\n",
    "            # Create report header\n",
    "            report_sections = [\n",
    "                \"# Comprehensive Security Analysis Report\\n\",\n",
    "                f\"## Repository: {Path(self.repo_path).name}\\n\",\n",
    "                f\"### Analysis Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\\n\",\n",
    "            ]\n",
    "\n",
    "            # Analyze each category separately\n",
    "            category_analyses = []\n",
    "            for category, files in files_by_category.items():\n",
    "                if not files:\n",
    "                    continue\n",
    "\n",
    "                print(f\"\\nAnalyzing {category} files...\")\n",
    "                try:\n",
    "                    analysis = self._analyze_category(category, files)\n",
    "                    category_analyses.append(\n",
    "                        f\"\\n## {category.title()} Security Analysis\\n{analysis}\"\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"Error analyzing {category}: {str(e)}\")\n",
    "                    category_analyses.append(\n",
    "                        f\"\\n## {category.title()} Security Analysis\\nAnalysis failed: {str(e)}\"\n",
    "                    )\n",
    "\n",
    "                # Add delay between categories\n",
    "                time.sleep(2)\n",
    "\n",
    "            # Add category analyses to report\n",
    "            report_sections.extend(category_analyses)\n",
    "\n",
    "            # Generate cross-cutting summary\n",
    "            try:\n",
    "                summary_prompt = \"\"\"\n",
    "                    Based on the above category-specific analyses, provide a high-level security assessment focusing on:\n",
    "\n",
    "                    1. EXECUTIVE SUMMARY\n",
    "                    2. CROSS-CUTTING CONCERNS\n",
    "                    3. CRITICAL PATTERNS\n",
    "                    4. KEY RECOMMENDATIONS\n",
    "\n",
    "                    Use proper Markdown formatting.\n",
    "                 \"\"\"\n",
    "\n",
    "                summary = self.model.generate_content(\n",
    "                    summary_prompt + \"\\n\\n\" + \"\\n\".join(category_analyses[-1000:])\n",
    "                )\n",
    "                report_sections.extend([\"\\n## Cross-Cutting Analysis\\n\", summary.text])\n",
    "            except Exception as e:\n",
    "                print(f\"Error generating summary: {str(e)}\")\n",
    "\n",
    "            # Write report\n",
    "            report_content = \"\\n\".join(report_sections)\n",
    "            report_path.write_text(report_content, encoding=\"utf-8\")\n",
    "            print(f\"\\nSecurity analysis report generated: {report_path}\")\n",
    "            return str(report_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error during security analysis: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            report_sections.extend([\"\\n## Error During Analysis\\n\", f\"```\\n{error_msg}\\n```\"])\n",
    "            report_path.write_text(\"\\n\".join(report_sections), encoding=\"utf-8\")\n",
    "            return str(report_path)\n",
    "\n",
    "    def cleanup(self):\n",
    "        \"\"\"Clean up temporary files.\"\"\"\n",
    "        if self.repo_path and Path(self.repo_path).exists():\n",
    "            import shutil\n",
    "\n",
    "            shutil.rmtree(self.temp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Security Analysis\n",
    "\n",
    "In this section, we'll conduct a thorough security analysis of the FastAPI repository using our analyzer. FastAPI was chosen as our test case for several compelling reasons:\n",
    "\n",
    "1. **Modern Python Framework:** FastAPI is a modern, fast web framework for building APIs with Python, making it an excellent real-world test case\n",
    "2. **Large Active Codebase:** With over 60k stars on GitHub, it represents a production-grade codebase with real security considerations\n",
    "3. **Complex Dependencies:** Features integration with various components like Pydantic, Starlette, and authentication systems\n",
    "4. **Security-Critical:** As a web framework, FastAPI's security practices directly impact thousands of production applications\n",
    "5. **Well-Documented:** Its comprehensive documentation allows us to validate our analysis against known security patterns\n",
    "\n",
    "Our analysis will focus on identifying potential security vulnerabilities across different components of the framework, from core routing logic to authentication mechanisms and dependency management. We'll use Gemini 1.5 Pro's capabilities to analyze both the code and its surrounding infrastructure, providing insights that could benefit the broader FastAPI community.\n",
    "Let's proceed with the analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing code files...\n",
      "\n",
      "Analyzing config files...\n",
      "\n",
      "Analyzing docker files...\n",
      "\n",
      "Analyzing dependencies files...\n",
      "\n",
      "Analyzing documentation files...\n",
      "Error analyzing documentation: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 4. Meaning that the model was reciting from copyrighted material.\n",
      "\n",
      "Security analysis report generated: security_analysis_fastapi.git.md\n"
     ]
    }
   ],
   "source": [
    "# Initialize the security analyzer\n",
    "api_key = \"AIzaSyCzqaQ3CIbH8kTl9KJ6kuPtgFV-qzi3PPU\"\n",
    "analyzer = ComprehensiveSecurityAnalyzer(\n",
    "    gemini_api_key=api_key,\n",
    ")\n",
    "\n",
    "# Clone a repository and analyze security\n",
    "analyzer.clone_repository(repo_url=\"https://github.com/fastapi/fastapi.git\")\n",
    "analyzer.analyze_security()\n",
    "\n",
    "# Clean up temporary files\n",
    "analyzer.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the generated report. The report should provide a comprehensive security analysis of the repository, including detailed findings and recommendations for each category of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Comprehensive Security Analysis Report\n",
       "\n",
       "## Repository: fastapi.git\n",
       "\n",
       "### Analysis Date: 2024-11-28 01:18:09\n",
       "\n",
       "\n",
       "\n",
       "## Code Security Analysis\n",
       "## Security Analysis of FastAPI Codebase\n",
       "\n",
       "Here's a security analysis of the provided FastAPI codebase, categorized by severity level and followed by recommendations.\n",
       "\n",
       "**1. CRITICAL FINDINGS**\n",
       "\n",
       "* **None:** The provided codebase does not exhibit any critical security vulnerabilities based on the provided code snippets. \n",
       "\n",
       "**2. HIGH-RISK ISSUES**\n",
       "\n",
       "* **Potential Sensitive Data Exposure (tests/test_security_http_basic_optional.py, tests/test_security_http_basic_realm_description.py, tests/test_security_http_basic_realm.py, tests/test_security_http_basic.py, tests/test_security_oauth2.py):** Several test files store and expose user credentials (`username`, `password`) in plain text within the response. While this is within test environments, it's a bad practice that could accidentally leak into production code.\n",
       "\n",
       "**3. MEDIUM CONCERNS**\n",
       "\n",
       "* **pdm_build.py - Overwriting Metadata from Environment:** This file overrides package metadata using values from an environment variable (`TIANGOLO_BUILD_PACKAGE`). While convenient, this could be misused to inject malicious code or alter package behavior if the environment variable is compromised. \n",
       "* **tests/test_custom_middleware_exception.py - Hardcoded Error Codes:**  The `ContentSizeLimitMiddleware` uses a hardcoded error code (`999`). This can make troubleshooting more difficult and potentially reveal internal system details.\n",
       "* **tests/test_ws_router.py - Potential Unhandled WebSocket Exceptions:** The  `websocket_middleware` function in `test_depend_err_middleware` catches all exceptions (`except Exception`) and closes the WebSocket with a reason. This could potentially leak sensitive information in the reason string if an unexpected exception occurs. \n",
       "\n",
       "**4. RECOMMENDATIONS**\n",
       "\n",
       "* **Never Store Credentials in Plain Text:** In test files or production code, avoid storing or displaying user credentials in plain text. Use hashing or encryption for sensitive data.\n",
       "* **Parameterize or Obfuscate Sensitive Configurations:** Avoid hardcoding sensitive information in code, especially if it relates to paths, secrets, or internal system details.  Use configuration files or environment variables, and consider obfuscating values where appropriate.\n",
       "* **Specific Exception Handling:** Avoid generic `except Exception` blocks. Catch specific exceptions to control the error handling flow and prevent unintended information disclosure.  Log exceptions securely with appropriate context for debugging without revealing sensitive data.\n",
       "* **Input Sanitization:** While FastAPI handles basic data validation through Pydantic, for specific security contexts like file uploads or user-generated content, consider adding extra layers of sanitization.\n",
       "* **Security Reviews:** Regularly review code, especially in security-critical areas, for potential vulnerabilities. Consider using automated security scanning tools as part of your development pipeline. \n",
       "* **Stay Updated:** Keep your FastAPI and Pydantic libraries updated to benefit from the latest security patches and improvements.\n",
       "\n",
       "**Additional Notes**\n",
       "\n",
       "* Many of the identified concerns exist in test files. While this doesn't directly impact production security, it's crucial to maintain secure coding practices even in test environments to prevent bad habits from leaking into production.\n",
       "* This analysis is based on the provided code snippets. A comprehensive security assessment would involve examining the entire codebase and its deployment environment. \n",
       "\n",
       "\n",
       "## Config Security Analysis\n",
       "## FastAPI Configuration File Security Analysis\n",
       "\n",
       "This analysis focuses on the security implications of the provided FastAPI configuration files.\n",
       "\n",
       "### 1. CRITICAL FINDINGS\n",
       "\n",
       "* **`check-yaml` with `--unsafe` flag:** The `.pre-commit-config.yaml` file utilizes the `check-yaml` hook with the `--unsafe` flag. This disables YAML schema validation, potentially allowing malicious code execution through specially crafted YAML files. (**CRITICAL**)\n",
       "\n",
       "    * **Impact:** Remote Code Execution (RCE) is possible if malicious YAML files are processed.\n",
       "\n",
       "### 2. HIGH-RISK ISSUES\n",
       "\n",
       "* **GitHub Actions Secrets:** Multiple GitHub Actions workflows (e.g., `smokeshow.yml`, `publish.yml`, `people.yml`, etc.) directly reference secrets like `GITHUB_TOKEN`, `FASTAPI_PEOPLE`, `SMOKESHOW_AUTH_KEY`, and `CLOUDFLARE_API_TOKEN`.  Hardcoding secrets within workflow files makes them visible in the repository history and exposes them to anyone with access. (**HIGH**)\n",
       "\n",
       "    * **Impact:** Compromise of these secrets could lead to unauthorized access to your GitHub repository, PyPI package publishing, Cloudflare Pages deployment, or external services associated with these keys.\n",
       "\n",
       "* **Hardcoded Sponsorship Tier List:** The `docs/en/data/sponsors_badge.yml` file contains a hardcoded list of sponsors classified into different tiers. While not directly exposing sensitive information, this might be considered undesirable as it could lead to disputes or issues related to sponsorship recognition. (**MEDIUM**)\n",
       "\n",
       "    * **Impact:** Potential for dissatisfaction among sponsors if tier assignments are perceived as unfair or inaccurate.\n",
       "\n",
       "### 3. MEDIUM CONCERNS\n",
       "\n",
       "* **Exposed Sponsor Information:** The `docs/en/data/sponsors.yml` file contains URLs and images related to sponsors. While not a direct security vulnerability, changes to these external resources could impact the documentation's appearance or functionality. (**MEDIUM**)\n",
       "\n",
       "    * **Impact:** Potential for broken links or visual inconsistencies in the documentation if sponsor resources change.\n",
       "\n",
       "### 4. RECOMMENDATIONS\n",
       "\n",
       "* **Remove `--unsafe` flag:** Immediately remove the `--unsafe` argument from the `check-yaml` hook in `.pre-commit-config.yaml`. Utilize a safe YAML schema validation approach to prevent potential code injection vulnerabilities.\n",
       "* **Use GitHub Secrets for Actions:** Migrate all hardcoded secrets used in GitHub Actions workflows to GitHub Secrets. This ensures that sensitive keys are stored securely and are not visible in the repository history.\n",
       "* **Reconsider Sponsor Tier Exposure:** Evaluate whether publicly exposing the sponsor tier list within the repository is necessary. Alternatives include generating the list dynamically or removing it entirely.\n",
       "* **Monitor External Sponsor Resources:** Implement a process to monitor changes in sponsor URLs and images to maintain the integrity of the documentation.\n",
       "\n",
       "By addressing these issues, you can significantly improve the security posture of your FastAPI project and its associated infrastructure. \n",
       "\n",
       "\n",
       "## Docker Security Analysis\n",
       "## Dockerfile Security Analysis\n",
       "\n",
       "Here's a security analysis of the provided Dockerfiles, formatted in Markdown:\n",
       "\n",
       "### 1. CRITICAL FINDINGS\n",
       "\n",
       "* **Outdated Base Image:** Both Dockerfiles use `python:3.9`, which might contain known vulnerabilities.\n",
       "* **Unpinned Dependencies:** The `pip install` commands don't specify exact versions for some dependencies (e.g., `httpx`, `PyGithub`). This can lead to unpredictable builds and potential vulnerabilities if new versions introduce security issues.\n",
       "* **Lack of Vulnerability Scanning:** No mention of image vulnerability scanning during or after the build process.\n",
       "\n",
       "### 2. HIGH-RISK ISSUES\n",
       "\n",
       "* **Running as root:** The `CMD [\"python\", \"/app/main.py\"]` instruction will execute the application as the root user inside the container. This provides excessive privileges and increases the impact of potential vulnerabilities.\n",
       "\n",
       "### 3. MEDIUM CONCERNS\n",
       "\n",
       "* **No Multi-stage Builds:**  While not critical for these simple Dockerfiles, multi-stage builds would improve layer optimization and potentially reduce the final image size. \n",
       "* **No Explicit Resource Limits:** No resource limits (CPU, memory) are defined, potentially allowing containers to consume excessive resources.\n",
       "\n",
       "### 4. RECOMMENDATIONS\n",
       "\n",
       "* **Use a Minimal Base Image:** Consider a slimmer base image like `python:3.9-slim` or even a distroless image to minimize the attack surface.\n",
       "* **Pin Dependency Versions:** Specify exact versions for all dependencies in the `requirements.txt` file and use it for installation:\n",
       "    ```dockerfile\n",
       "    COPY requirements.txt /app/requirements.txt\n",
       "    RUN pip install --no-cache-dir -r /app/requirements.txt\n",
       "    ```\n",
       "* **Implement Vulnerability Scanning:** Integrate a vulnerability scanner like Trivy or Snyk into the CI/CD pipeline to detect vulnerabilities in the base image and dependencies. \n",
       "* **Run as Non-root User:** Create a dedicated user and group in the Dockerfile and switch to them before running the application:\n",
       "    ```dockerfile\n",
       "    RUN addgroup --system appgroup && adduser --system --group appgroup appuser\n",
       "    USER appuser\n",
       "    ```\n",
       "* **Set Resource Limits:** Define resource limits using Docker Compose or Kubernetes configurations to prevent resource exhaustion attacks.\n",
       "* **Leverage Multi-Stage Builds:** If the application involves build steps, use multi-stage builds to separate the build environment from the runtime environment, resulting in a smaller final image.\n",
       "* **Minimize Build Context:** Use `.dockerignore` to exclude unnecessary files from the build context, reducing the image size and potential attack surface.\n",
       "* **Sign and Verify Images:** Implement image signing and verification to ensure image authenticity and prevent unauthorized modifications. \n",
       "\n",
       "**By addressing these recommendations, you can significantly improve the security posture of your Docker images and minimize potential risks.** \n",
       "\n",
       "\n",
       "## Dependencies Security Analysis\n",
       "## Analysis of requirements.txt\n",
       "\n",
       "This `requirements.txt` file specifies dependencies for a Python project. Let's analyze it from a security perspective.\n",
       "\n",
       "### 1. CRITICAL FINDINGS\n",
       "\n",
       "- **No evidence of vulnerability scanning or CVE monitoring:** The file lacks any indication of using tools to actively scan for known vulnerabilities in listed packages or to monitor for newly disclosed CVEs. This omission represents a critical security gap, potentially leaving the project exposed to known exploits.\n",
       "\n",
       "### 2. HIGH-RISK ISSUES\n",
       "\n",
       "- **Loose version constraints:** While `pre-commit` is pinned to a specific range (`>=2.17.0,<5.0.0`), the inclusion of other `requirements` files (`requirements-tests.txt`, `requirements-docs.txt`) without specifying their versions introduces a significant risk. These files might contain packages with loose constraints, allowing the installation of versions with known vulnerabilities.\n",
       "- **Playwright version unpinned:**  The comment indicates Playwright is used for generating screenshots, but its version is completely unpinned. This allows the installation of any Playwright version, including those with potential security flaws.\n",
       "- **Lack of package source verification:** There's no indication of measures to verify the authenticity and integrity of packages during installation. This leaves the project vulnerable to supply chain attacks, where malicious code could be injected into dependencies.\n",
       "\n",
       "### 3. MEDIUM CONCERNS\n",
       "\n",
       "- **No explicit mention of development vs. production dependencies:** Although separate files for testing and documentation dependencies are included, there's no clear distinction between development and production dependencies. This can lead to unnecessary packages being included in production deployments, potentially expanding the attack surface.\n",
       "\n",
       "### 4. RECOMMENDATIONS\n",
       "\n",
       "- **Implement vulnerability scanning:** Integrate a tool like Snyk, Dependabot, or OWASP Dependency-Check into the development workflow to automatically scan dependencies for known vulnerabilities.\n",
       "- **Pin all dependency versions:**  Use explicit version numbers for all packages, including those in `requirements-tests.txt` and `requirements-docs.txt`, to prevent the installation of vulnerable versions.\n",
       "- **Utilize a private package repository:**  Consider using a private package repository like JFrog Artifactory or Sonatype Nexus to store and manage dependencies, allowing for better control and security.\n",
       "- **Enable package source verification:** Configure the package manager (pip) to verify the origin and integrity of packages using checksums or digital signatures.\n",
       "- **Enforce a strict dependency update process:**  Establish a documented process for updating dependencies, including reviews for security implications and testing before deployment.\n",
       "- **Monitor security advisories:** Stay informed about security advisories related to the used packages and react promptly to identified vulnerabilities by updating or patching affected dependencies.\n",
       "- **Clearly separate development and production dependencies:** Create separate `requirements` files for development and production environments, minimizing the attack surface in production deployments.\n",
       "- **Minimize dependencies:** Regularly review dependencies to identify and remove unused or unnecessary packages, reducing the overall risk associated with dependencies.\n",
       "\n",
       "By addressing these recommendations, you can significantly strengthen the security posture of your Python project and mitigate the risks associated with dependencies.\n",
       "\n",
       "\n",
       "## Documentation Security Analysis\n",
       "Analysis failed: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part`, but none were returned. The candidate's [finish_reason](https://ai.google.dev/api/generate-content#finishreason) is 4. Meaning that the model was reciting from copyrighted material.\n",
       "\n",
       "## Cross-Cutting Analysis\n",
       "\n",
       "## FastAPI Codebase Security Assessment\n",
       "\n",
       "### 1. Executive Summary\n",
       "\n",
       "This security assessment analyzes the provided FastAPI codebase, focusing on code and configuration files. While no critical vulnerabilities were found in the code itself, the analysis revealed a **CRITICAL** security misconfiguration in a YAML validation hook and **HIGH** risks related to exposed secrets in GitHub Actions workflows. Addressing these issues is paramount to ensure the application's security. \n",
       "\n",
       "### 2. Cross-Cutting Concerns\n",
       "\n",
       "* **Secure Handling of Sensitive Data:**  Both code and configurations should prioritize secure handling of credentials, API keys, and other sensitive data. \n",
       "* **Secure Configuration Practices:** Avoid hardcoding sensitive information, especially within version control. Utilize environment variables or secure configuration management systems.\n",
       "* **Exception Handling and Logging:** Implement robust exception handling to prevent information disclosure and log security-related events appropriately without exposing sensitive data. \n",
       "\n",
       "### 3. Critical Patterns\n",
       "\n",
       "* **YAML Validation Hook Misconfiguration (.pre-commit-config.yaml):** The use of the `--unsafe` flag with `check-yaml` disables essential security checks and exposes the application to potential remote code execution.\n",
       "* **Exposed Secrets in GitHub Actions:** Multiple workflows directly reference secrets, making them visible in the repository history and vulnerable to compromise.\n",
       "\n",
       "### 4. Key Recommendations\n",
       "\n",
       "* **Immediately remove the `--unsafe` flag from the `check-yaml` hook and implement a secure YAML schema validation strategy.**\n",
       "* **Migrate all hardcoded secrets from GitHub Actions workflows to GitHub Secrets for secure storage.**\n",
       "* **Review test files for the exposure of user credentials and replace plain text storage with hashing or encryption.**\n",
       "* **Implement parameterization or obfuscation for sensitive configurations within the codebase.**\n",
       "* **Avoid generic exception handling and log exceptions securely without revealing sensitive information.**\n",
       "* **Consider additional input sanitization for security-sensitive operations.**\n",
       "* **Regularly perform security reviews and consider using automated security scanning tools.**\n",
       "\n",
       "Addressing these recommendations will significantly enhance the security posture of the FastAPI codebase. It is highly recommended to implement these changes as a priority to minimize security risks. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Report file location: ./security_analysis_fastapi.git.md\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "\n",
    "def display_analysis_report(report_path: str):\n",
    "    \"\"\"Display the security analysis report in the notebook.\"\"\"\n",
    "    try:\n",
    "        report_content = Path(report_path).read_text(encoding='utf-8')\n",
    "        display(Markdown(report_content))\n",
    "        print(f\"\\nReport file location: {report_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading report: {str(e)}\")\n",
    "        \n",
    "display_analysis_report(report_path=\"./security_analysis_fastapi.git.md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "This notebook demonstrates the powerful capabilities of combining Large Language Models (specifically Gemini 1.5 Pro) with traditional security analysis approaches for comprehensive codebase security assessment. Through our analysis of FastAPI, we've shown how the `ComprehensiveSecurityAnalyzer` can effectively process and analyze diverse file types, detect potential security vulnerabilities, and provide actionable insights. The tool's ability to understand context across multiple files and identify cross-cutting security patterns makes it a valuable addition to existing security workflows.\n",
    "While LLM-based analysis should not replace traditional security tools and human expertise, it serves as a powerful complementary tool that can:\n",
    "\n",
    "- Rapidly process large codebases\n",
    "- Identify non-obvious security patterns\n",
    "- Provide context-aware recommendations\n",
    "- Help prioritize security concerns\n",
    "- Support security teams in making informed decisions\n",
    "\n",
    "Future improvements could include integration with vulnerability databases, custom security rule definitions, CI/CD pipeline integration, enhanced prompting, and expanded support for additional programming languages. As LLM capabilities continue to evolve, tools like this will become increasingly valuable for maintaining robust security practices in modern software development."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
